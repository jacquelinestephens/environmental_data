print(num_vec)
num_vec_matrix1 = matrix(num_vec, nrow = 2, ncol = 3,
byrow = TRUE,
dimnames = list(c("R1","R2"), c("C1","C2","C3")))
num_vec_matrix2 = matrix(num_vec, nrow = 2, ncol = 3,
byrow = FALSE,
dimnames = list(c("R1","R2"),c("C1","C2","C3")))
print(num_vec_matrix1)
print(num_vec_matrix2)
#after printing both, you can see that the byrow= argument controls whether elements will be listed vertically (TRUE) or horizontally (FALSE)
#dimnames = names both your rows and columns
#creates data frames of vectors of same lengths
num_vec1 = c(5,6,10,6,3,9,8,5)
num_vec2 = rep(1:2, 4)#repeat 1 to 2 four times
length(num_vec1)
length(num_vec2)
data.frame(num_vec1,num_vec2)
nrow(ginkgo)#number of rows or observations
ncol(ginkgo)#number of columns
dim(ginkgo)#dimensions of the data frame: rows columns
# use the $ to select a specific column of the data frame
notch_depth = ginkgo$notch_depth
#use [] to subset by position within the data frame
ginkgo[1]#calls out the first entire column
ginkgo[2,3]#first number selects the row, second number selects the column
ginkgo[3]#calls out the third entire column
ginkgo[1,]#calls out the entire row of the first observation
#use subset() to create a data frame of just adelie species
dat_adelie = subset(penguins, species == "Adelie")
#subset(data frame, column name == "specific value")
#the summary() function will give you the minimum, median, mean, maximum, and 1st and 3rd quantile values of each column
summary(ginkgo)
#because seeds_present was a character value it counts the total FALSE and TRUEs present
summary(penguins)
#the mean() function only accepts numeric or logical values
mean(ginkgo$max_width, na.rm = TRUE)
mean(penguins$body_mass_g, na.rm = TRUE) #adding the na.rm = argument may be necessary if your column contains NAs
#should missing values be removed?
#the standard deviation function
sd(ginkgo$max_width, na.rm = TRUE)
sd(penguins$body_mass_g,na.rm = TRUE)
plot(x = ginkgo$max_depth,y = ginkgo$max_width,
main = "Maximum Leaf Depth by Leaf Width In Ginkgos",
xlab = "Maximum Leaf Depth",
ylab = "Maximum Leaf Width",
ylim = c(10, 150),
xlim = c(10,150),
pch = 1,
cex = 0.5,
col = "green")
summary(penguins$flipper_length_mm)
hist(penguins$flipper_length_mm,
main = "Distribution of Flipper Length",
xlab = "Flipper Length (mm)",
breaks =  10)
par(mfrow = c(2, 2))#the c(2,2) means 2 rows of 2 columns for plots
boxplot(ginkgo$petiole_length,
main = "Ginkgo Petiole Length",
ylab = "Petiole Length (mm)")
boxplot(ginkgo$max_width,
main = "Ginkgo Max Width",
ylab = "Max Width (mm)")
boxplot(ginkgo$petiole_length ~ ginkgo$seeds_present,
main = "Petiole Length Conditioned By \nSeed Presence",
xlab = "Seed Present",
ylab = "Max Width (mm)")
boxplot(ginkgo$max_width ~ ginkgo$seeds_present,
main = "Max Width Conditioned By Seed Presence",
xlab = "Seed Present",
ylab = "Max Width (mm)")
#If mean or sd are not specified they assume the default values of 0 and 1
#probability density function
#is a value of 4 or 5 more likely?
#dnorm(x, mean = 0, sd = 1, log = FALSE)
dnorm(5, mean = 10, sd = 2.5)
dnorm(4, mean = 10, sd = 2.5)
#cumulative density function
#What is the prob of observing 5 or less?
#pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
pnorm(5, mean = 10, sd = 2.5) #prob of 5 or less
1 - pnorm(5, mean = 10, sd = 2.5) #prob of five or more
#quantile function
#what is the 20th percentile of lengths?
#qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
qnorm(.2, mean = 10, sd = 2.5)
#10 plots and from earlier observations 1/4 chance of success
#probability mass function
#dbinom(x, size, prob, log = FALSE)
#what is the prob of observing a value of exactly 4?
dbinom(4, size =  10, prob = .25)
#cumulative mass function
#what is the prob of observing a value of 4 or less? or more?
#pbinom(q, size, prob, lower.tail = TRUE, log.p = FALSE)
pbinom(4, size =  10, prob = .25)
1-pbinom(4, size =  10, prob = .25)
#quantile function
#what is the median or 50th percentile? 90th percentile?
qbinom(0.5, size = 10, prob = .25)
[Final Project: R Reference Guide](final_R_reference.html)
Final Project: R Reference Guide(final_R_reference.html)
[Final Project: R Reference Guide(final_R_reference.html)]
[Final Project: R Reference Guide](final_R_reference.html)
require(here)
delomys_dat = read.csv(here("data","delomys.csv"))
head(delomys_dat)#figure out what column body mass and length are
summary(delomys_dat[4]) #summary statistics for body mass
summary(delomys_dat[5]) #summary statistics for body length
#test for normality (shapiro-Wilk test is one sample test)
shapiro.test(delomys_dat$body_mass)
shapiro.test(delomys_dat$body_length)
#null hyp for shapiro = data sampled from a normally distributed population
#low p-values suggest that there is good evidence against null
#review using models 1 assignment
plot(delomys_dat$body_mass, delomys_dat$body_length,
xlab = "Body Mass", ylab = "Body Length")
hist(delomys_dat$body_mass, xlab = "Body Mass", main = "Histogram of Body Mass")
hist(delomys_dat$body_length, xlab = "Body Length", main = "Histogram of Body Length")
boxplot(body_mass ~ binomial, data = delomys_dat, xlab = "Species", ylab = "Body Mass")
boxplot(body_mass ~ sex, data = delomys_dat, xlab = "Sex", ylab = "Body Mass")
boxplot(body_mass ~ binomial*sex, data = delomys_dat, xlab = "", ylab = "Body Mass")
plot(delomys_dat$body_mass, delomys_dat$body_length,
xlab = "Body Mass", ylab = "Body Length")
hist(delomys_dat$body_mass, xlab = "Body Mass", main = "Histogram of Body Mass")
hist(delomys_dat$body_length, xlab = "Body Length", main = "Histogram of Body Length")
boxplot(body_mass ~ binomial, data = delomys_dat, xlab = "Species", ylab = "Body Mass", main = "Body Mass Conditioned by Species")
boxplot(body_mass ~ sex, data = delomys_dat, xlab = "Sex", ylab = "Body Mass", main = "Body Mass Conditioned by Sex")
boxplot(body_mass ~ binomial*sex, data = delomys_dat, xlab = "", ylab = "Body Mass",main = "Body Mass Conditioned by Species and Sex")
boxplot(body_mass ~ binomial, data = delomys_dat, xlab = "Species", ylab = "Body Mass", main = "Body Mass Conditioned by Species")
boxplot(body_mass ~ sex, data = delomys_dat, xlab = "Sex", ylab = "Body Mass", main = "Body Mass Conditioned by Sex")
boxplot(body_mass ~ binomial*sex, data = delomys_dat, xlab = "", ylab = "Body Mass",main = "Body Mass Conditioned by Species and Sex")
require(here)
delomys_dat = read.csv(here("data","delomys.csv"))
head(delomys_dat)#figure out what column body mass and length are
summary(delomys_dat[4]) #summary statistics for body mass
summary(delomys_dat[5]) #summary statistics for body length
#test for normality (shapiro-Wilk test is one sample test)
shapiro.test(delomys_dat$body_mass)
shapiro.test(delomys_dat$body_length)
#null hyp for shapiro = data sampled from a normally distributed population
#low p-values suggest that there is good evidence against null
#review using models 1 assignment
# use the $ to select a specific column of the data frame
notch_depth = ginkgo$notch_depth
#install packages with the name of the package in quote marks if you do not already have the base package
#install.packages("here")
#install.packages("palmerpenguins")
require(here)
require(palmerpenguins)
ginkgo = read.csv(here("data","ginkgo_data_2021.csv"))
#here() calls out where to get the file using quotation marks as well as the .csv at the end
#read.csv() reads the file into a data.frame
#setting it equal to ginkgo= gives the data frame a name
## Create a vector of numbers
num_vec  = c(1, 4, 8, 9, 13,17)
## Create a vector of characters
char_vec = c("a", "fish", "data is cool")
#have to put the character elements in quotation marks
#both typing the name of the vector into the console as well as using the print() prints the contents
num_vec
print(num_vec)
char_vec
print(char_vec)
length(num_vec)#length or count of elements in the vector
length(char_vec)#length or count of elements in the vector
#creating a matrix from the vector of numbers
print(num_vec)
num_vec_matrix1 = matrix(num_vec, nrow = 2, ncol = 3,
byrow = TRUE,
dimnames = list(c("R1","R2"), c("C1","C2","C3")))
num_vec_matrix2 = matrix(num_vec, nrow = 2, ncol = 3,
byrow = FALSE,
dimnames = list(c("R1","R2"),c("C1","C2","C3")))
print(num_vec_matrix1)
print(num_vec_matrix2)
#after printing both, you can see that the byrow= argument controls whether elements will be listed vertically (TRUE) or horizontally (FALSE)
#dimnames = names both your rows and columns
nrow(ginkgo)#number of rows or observations
ncol(ginkgo)#number of columns
dim(ginkgo)#dimensions of the data frame: rows columns
# use the $ to select a specific column of the data frame
notch_depth = ginkgo$notch_depth
#use [] to subset by position within the data frame
ginkgo[1,]#calls out the entire row of the first observation
ginkgo[2,3]#first number selects the row, second number selects the column
ginkgo[,3]#calls out the third entire column
#use subset() to create a data frame of just adelie species
dat_adelie = subset(penguins, species == "Adelie")
#subset(data frame, column name == "specific value")
ginkgo[3]#calls out the third entire column
View(ginkgo)
View(ginkgo)
[Final Project: R Reference Guide](final_R_reference.html)
[Final Project: R Reference Guide](final_R_reference.html)
[Final Project: R Reference Guide](final_R_reference.html)
#Fitting a LOWESS Model
fit_lowess_50 = loess(power~sample_size, data = sim_sample_size, span = 0.5)
#use predict() to create a data.frame of new values for plotting my smoother
newdata_sample_size = data.frame(sample_size = seq(2, 20, length.out = 100))
plot(
x = newdata_sample_size$sample_size,
y = predict(fit_lowess_50, newdata = newdata_sample_size),
type = "l",
ylab = "Statistical Power", xlab = "Sample Size") #plot it!
#from lab 5
require(here)
dat_dispersal = read.csv(here("data", "dispersal.csv"))
ricker_fun = function(x, a, b)
{
return(a * x * exp(-b * x))
}
curve(
ricker_fun(x, 1, 1),
from = 0, to = 5, add = FALSE,
main = "Ricker function: a = 1, b = 1",
ylab = "f(x)", xlab = "x")
exp_fun = function(x, a, b)
{
return(a * exp(-b*x))
}
curve(
exp_fun(x, 0.1, 1),
from = 0, to = 10, add = FALSE,
main = "Exponential function: a = 1, b = 1",
ylab = "f(x)", xlab = "x")
plot(
dat_dispersal$dist.class,
dat_dispersal$disp.rate.ftb,
xlim = c(0,1500),
xlab = "Distance Class",
ylab = "Standardized Dispersal Rate",
main = "Marbled Salamander - first time breeders\n Ricker Model")
curve( ricker_fun(x, 0.011, 0.0045), add = TRUE,
lty  = 1, col= "blue")
fit_ricker_nls = nls(
disp.rate.ftb ~ ricker_fun(dist.class, a, b),
data = dat_dispersal,
start = list(b = 0, a = 1)) #use start to provide a starting parameter value from which to search for the optimal values
summary(fit_ricker_nls)
#QUestion 2
#Plotting an NLS model
plot(
dat_dispersal$dist.class,
dat_dispersal$disp.rate.ftb,
xlim = c(0,1500),
xlab = "Distance Class",
ylab = "Standardized Dispersal Rate",
main = "Marbled Salamander - first time breeders",
pch = 16, col = "blue")
dist_newdata = data.frame(dist.class = seq(0, 1600, length.out = 1600))
lines(predict(fit_ricker_nls, newdata = dist_newdata)) #lines() adds to an existing plot
curve( ricker_fun(x, 0.011, 0.0045), add = TRUE,
lty  = 2, col= "red") #guess model we made visually
legend("topright", legend = c("observed", "nls fit", "guess"),
lty = c(NA,1,2), pch = c(16, NA, NA),
col = c("blue", "black", "red")) #addition to the legend
#Logistic Regression, review of bird presence/absence in lab 3
#hermit Warbler Presence/Absence
require(here)
dat_bird = read.csv(here("data", "bird.sta.csv"))
dat_habitat = read.csv(here("data", "hab.sta.csv"))
dat_all = merge(dat_bird, dat_habitat)#merge data files to create complete dataset
dat_all$HEWA_pres = dat_all$HEWA > 0 #make a vector of presence/absence data for hermit warblers
# Hermit warbler presence/absence
dat_all$HEWA_pres = dat_all$HEWA > 0
#we know group 1 models dont work for binary response variables
# Create model fits
fit_hewa_slope = glm(HEWA_pres ~ slope, data = dat_all, family = binomial)
fit_hewa_ba_tot = glm(HEWA_pres ~ ba.tot, data = dat_all, family = binomial)
fit_hewa_both_additive = glm(HEWA_pres ~ slope + ba.tot, data = dat_all, family = binomial)
fit_hewa_both_interactive = glm(HEWA_pres ~ slope * ba.tot, data = dat_all, family = binomial)
summary(fit_hewa_both_additive)
#Plotting a fitted simple logistic model
#use the predict() to predict response values for a given set of predictor values
#we have to decide whether we want to predict the outcomes (P/A) or the probability of success
#we want probability of success
#make a dataframe that contains a sequence of new slopes
n = 500
slope_newdata = data.frame(
slope = seq(
from = min(dat_all$slope, na.rm = T),
to = max(dat_all$slope, na.rm = T),
length.out = n
)#used na.rm to avoid issues with missing data
)#used the min and max from observed values of slope in original data
#new dataframe for total basal area values for predictions
ba_newdata = data.frame(ba.tot = seq(from = min(dat_all$ba.tot, na.rm = T),
to = max(dat_all$ba.tot, na.rm = T),
length.out = n))
#now use predict to create model predictions
slope_newdata$hewa_predicted = predict( fit_hewa_slope, newdata = slope_newdata,type = "response")
#added predicted values as new columns to data frame
ba_newdata$hewa_predicted = predict(fit_hewa_ba_tot,newdata = ba_newdata, type = "response")
#Plotting the models 1 tab
par(mfrow = c(2, 1))
# Presence/absence data, translucent points:
plot(
HEWA_pres ~ slope, data = dat_all, yaxt = "n",
main = "HEWA Presence Related to \n Percent Slope",
xlab = "Percent Slope",
ylab = "",
pch = 16, cex = 1.5, col = gray(0, 0.05)
)
lines(hewa_predicted ~ slope, data = slope_newdata)
axis(2, at = c(0, 1), las = 1, labels = c("Absent", "Present"))
plot(
HEWA_pres ~ ba.tot, data = dat_all, yaxt = "n",
main = "HEWA Presence Related to \n Basal Area",
xlab = "Basal Area",
ylab = "",
pch = 16, cex = 1.5, col = gray(0, 0.05)
)
lines(hewa_predicted ~ ba.tot, data = ba_newdata)
axis(2, at = c(0, 1), las = 1, labels = c("Absent", "Present"))
#Plotting Both Parameters using AIC
AIC(
fit_hewa_ba_tot,
fit_hewa_slope,
fit_hewa_both_additive,
fit_hewa_both_interactive)
#additive and interactive models have the lowest AIC values
#plot the response with two parameters using 3D plot to make an interactive perspective plot
#first set up data on which to make predictions with a data frame that includes columns for both predictors: total basal area and slope
n = 50
#create sequences of values for both predictors
ba.tot = seq(
from = min(dat_all$ba.tot, na.rm = T),
to = max(dat_all$ba.tot, na.rm = T),
length.out = n)
slope = seq(
from = min(dat_all$slope, na.rm = T),
to = max(dat_all$slope, na.rm = T),
length.out = n)
#take advantage of the expand.grid() to make a data.frame that contains every combination of the two predictors
new_dat_all = expand.grid(
ba.tot = ba.tot,
slope = slope)
head(new_dat_all)
tail(new_dat_all)
#now use predict to make a vector of the model predictions
new_dat_all$pred_add = predict(
fit_hewa_both_additive,
newdata = new_dat_all,
type = "response")
new_dat_all$pred_int = predict(
fit_hewa_both_interactive,
newdata = new_dat_all,
type = "response")
#because contour and 3D plotting methods require matrices for the data on the z axis
z_hewa_add = matrix(
new_dat_all$pred_add,
nrow = length(ba.tot),
byrow = FALSE)
z_hewa_int = matrix(
new_dat_all$pred_int,
nrow = length(ba.tot),
byrow = FALSE)
require(rgl)
rgl::persp3d(
x = ba.tot,
y = slope,
z = z_hewa_add,
col = "steelblue",
xlab = "Basal Area",
ylab = "Slope",
zlab = "Pr(present)",
alpha = 0.4)
rglwidget()
install.packages("rgl")
require(rgl)
persp3d(  x = ba.tot,
y = slope,
z = z_hewa_add,
xlab = "Basal Area", ylab = "Slope", zlab = "Pr(present)",
col = 'lightblue',
theta = 30, phi = 30, expand = .75,
ticktype = 'detailed')
#saving an interactive plot using the rgl function
require(htmlwidgets)
install.packages("rgl")
saveWidget(
rglwidget(),
file = here("n_effect_size_power_sim_plot.html"),
selfcontained = TRUE
)
install.packages("rgl")
install.packages("rgl")
#Contour Plots
par(mfrow = c(1, 2))
contour(
x = ba.tot, y = slope,
z = z_hewa_add,
xlab = "Total Basal Area",
ylab = "Percent Slope",
main = "Additive")
contour(
x = ba.tot,
y = slope,
z = z_hewa_int,
xlab = "Total Basal Area",
ylab = "Percent Slope",
main = "Interactive")
#Simulating Sample sizes: we can do the same thing for a gradient in sample sizes
require(here)
bird = read.csv(here("data", "bird.sub.csv"))
hab = read.csv(here("data", "hab.sub.csv"))
birdhab = merge(bird,hab, by = c("basin", "sub"))
dim(birdhab)
#Question 1
alpha = 0.05
n_sims = 30
p_vals = numeric(n_sims)
sample_sizes = seq(2, 20)
sample_size_powers = numeric(length(sample_sizes))
# The maximum x value in the simulation.
# Use the maximum observed x-value in the data
max_x = max(birdhab$ls)
for(j in 1:length(sample_sizes))
{
# A sequence of equally-spaced x-values:
x_vals = seq(0, max_x, length.out = sample_sizes[j])
for(i in 1:n_sims)
{
fit_sim = linear_sim_fit(
x = x_vals,
y_int = int_obs,
slope = slope_obs,
st_dev = sd_obs
)
p_vals[i] = summary(fit_sim)$coefficients[2, 'Pr(>|t|)']
}
sample_size_powers[j] = sum(p_vals < alpha) / n_sims
}
sim_sample_size =
data.frame(
sample_size = sample_sizes,
power       = sample_size_powers)
plot(
power ~ sample_size, data = sim_sample_size,
main = "Sample Size Simulation, reps = 30",
type = 'l', xlab = 'Sample size', ylab = 'Statistical Power')
#fitting a lowess model
fit_lowess_30 = loess(power ~ sample_size, data = sim_sample_size, span = 0.3)
newdata_sample_size = data.frame(sample_size = seq(2, 20, length.out = 100))
plot(
x = newdata_sample_size$sample_size,
y = predict(fit_lowess_30, newdata = newdata_sample_size),
type = "l",
main = "Sample Size/Power Simulation \nLOESS Smoother, 30%",
ylab = "Statistical Power", xlab = "Sample Size")
points(
x = sim_sample_size$sample_size,
y = sim_sample_size$power,
col = adjustcolor("blue", alpha = 0.3),
pch = 19)
legend(
"bottomright",
legend = c("Smoothed", "Original"),
lty = c(1, NA), pch = c(NA, 16),
col = c(1, adjustcolor("blue", alpha = 0.3)),
inset=c(0.1,0.25))
#species GCKI presence/absence as predicted by slope, total basal area, slope and basal area (additive), slope and basal area (interactive)
dat_all$GCKI_pres = dat_all$GCKI > 0
fit_gcki_slope = glm(GCKI_pres ~ slope, data = dat_all, family = binomial)
fit_gcki_ba_tot = glm(GCKI_pres ~ ba.tot, data = dat_all, family = binomial)
fit_gcki_both_additive = glm(GCKI_pres ~ slope + ba.tot, data = dat_all, family = binomial)
fit_gcki_both_interactive = glm(GCKI_pres ~ slope * ba.tot, data = dat_all, family = binomial)
#Question 3
AIC(fit_gcki_ba_tot, fit_gcki_slope,
fit_gcki_both_additive,
fit_gcki_both_interactive)
#QUestion 5
coef(fit_gcki_both_interactive)
summary(fit_gcki_both_interactive)
#Question 6-7
#Plotting the models 1 tab
n = 500
slope_newdata = data.frame(
slope = seq(
from = min(dat_all$slope, na.rm = T),
to = max(dat_all$slope, na.rm = T),
length.out = n
)#used na.rm to avoid issues with missing data
)#used the min and max from observed values of slope in original data
#new dataframe for total basal area values for predictions
ba_newdata = data.frame(ba.tot = seq(from = min(dat_all$ba.tot, na.rm = T),
to = max(dat_all$ba.tot, na.rm = T),
length.out = n))
#now use predict to create model predictions
slope_newdata$gcki_predicted = predict( fit_gcki_slope, newdata = slope_newdata,type = "response")
#added predicted values as new columns to data frame
ba_newdata$gcki_predicted = predict(fit_gcki_ba_tot,newdata = ba_newdata, type = "response")
par(mfrow = c(2, 1))
# Presence/absence data, translucent points:
plot(
GCKI_pres ~ slope, data = dat_all, yaxt = "n",
main = "GCKI Presence and Absence Related to \n Percent Slope",
xlab = "Percent Slope",
ylab = "",
ylim = c(-0.25, 1.25),
pch = 16, cex = 1, col = rgb(0,0,1, alpha = 0.05)
)
lines(gcki_predicted ~ slope, data = slope_newdata)
axis(2, at = c(0, 1), las = 1, labels = c("Absent", "Present"))
plot(
GCKI_pres ~ ba.tot, data = dat_all, yaxt = "n",
main = "GCKI Presence and Absence Related to \n Basal Area",
xlab = "Basal Area",
ylab = "",
ylim = c(-0.25, 1.25),
pch = 16, cex = 1, col = rgb(0,0,1, alpha = 0.05))
lines(gcki_predicted ~ ba.tot, data = ba_newdata)
axis(2, at = c(0, 1), las = 1, labels = c("Absent", "Present"))
